/home/zxy/miniconda3/envs/ssfn/lib/python3.10/site-packages/torch/distributed/launch.py:180: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
Training with a single process on 1 GPUs.
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_small_patch16_224_in21k created, param count:21774736
number of params for requires grad: 109072
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 260
Train: 0 [   0/7 (  0%)]  Loss: 2.814 (2.81)  Time: 4.297s,   29.79/s  (4.297s,   29.79/s)  LR: 1.000e-07  Data: 1.075 (1.075)
Train: 0 [   6/7 (100%)]  Loss: 3.016 (2.95)  Time: 0.210s,  609.89/s  (0.796s,  160.72/s)  LR: 1.000e-07  Data: 0.000 (0.154)
Test: [   0/575]  Time: 0.847 (0.847)  Loss:  2.8750 (2.8750)  Acc@1:  4.6875 ( 4.6875)  Acc@5: 32.8125 (32.8125)
Test: [  50/575]  Time: 0.078 (0.093)  Loss:  3.0801 (2.9447)  Acc@1:  3.1250 ( 5.8824)  Acc@5: 19.5312 (30.3002)
Test: [ 100/575]  Time: 0.078 (0.086)  Loss:  2.9824 (2.9424)  Acc@1: 10.1562 ( 6.1572)  Acc@5: 24.2188 (30.6621)
Test: [ 150/575]  Time: 0.078 (0.083)  Loss:  2.9238 (2.9467)  Acc@1: 10.9375 ( 5.9965)  Acc@5: 29.6875 (30.3394)
Test: [ 200/575]  Time: 0.078 (0.082)  Loss:  2.8984 (2.9448)  Acc@1:  8.5938 ( 6.1295)  Acc@5: 32.0312 (30.3172)
Test: [ 250/575]  Time: 0.078 (0.081)  Loss:  2.8750 (2.9428)  Acc@1:  7.0312 ( 6.2220)  Acc@5: 31.2500 (30.5590)
Test: [ 300/575]  Time: 0.079 (0.081)  Loss:  2.8887 (2.9419)  Acc@1:  7.0312 ( 6.2214)  Acc@5: 39.0625 (30.6219)
Test: [ 350/575]  Time: 0.079 (0.081)  Loss:  2.9531 (2.9419)  Acc@1:  8.5938 ( 6.2723)  Acc@5: 34.3750 (30.7002)
Test: [ 400/575]  Time: 0.079 (0.080)  Loss:  2.9473 (2.9425)  Acc@1: 10.1562 ( 6.2695)  Acc@5: 28.1250 (30.6675)
Test: [ 450/575]  Time: 0.079 (0.080)  Loss:  2.9707 (2.9430)  Acc@1:  3.1250 ( 6.1894)  Acc@5: 25.7812 (30.6195)
Test: [ 500/575]  Time: 0.079 (0.080)  Loss:  2.9121 (2.9431)  Acc@1:  5.4688 ( 6.1876)  Acc@5: 31.2500 (30.5826)
Test: [ 550/575]  Time: 0.079 (0.080)  Loss:  2.9609 (2.9434)  Acc@1:  4.6875 ( 6.1947)  Acc@5: 32.8125 (30.5113)
Test: [ 575/575]  Time: 0.078 (0.080)  Loss:  2.9922 (2.9438)  Acc@1:  0.7812 ( 6.1822)  Acc@5: 28.9062 (30.4769)
Current checkpoints:
 ('/mnt/SFT_store/zxy/vit_small_patch16_224_in21k/vtab/dsprites_loc/ssf/20240127-023943-vit_small_patch16_224_in21k-224/checkpoint-0.pth.tar', 6.182183159722222)

Train: 1 [   0/7 (  0%)]  Loss: 2.865 (2.86)  Time: 0.638s,  200.72/s  (0.638s,  200.72/s)  LR: 1.000e-03  Data: 0.422 (0.422)
Train: 1 [   6/7 (100%)]  Loss: 2.856 (2.86)  Time: 0.218s,  587.53/s  (0.277s,  462.78/s)  LR: 1.000e-03  Data: 0.000 (0.061)
Test: [   0/575]  Time: 0.582 (0.582)  Loss:  2.9062 (2.9062)  Acc@1:  3.9062 ( 3.9062)  Acc@5: 27.3438 (27.3438)
Test: [  50/575]  Time: 0.079 (0.089)  Loss:  2.7715 (2.8740)  Acc@1: 10.9375 ( 6.3419)  Acc@5: 42.9688 (31.3879)
Test: [ 100/575]  Time: 0.079 (0.084)  Loss:  2.8242 (2.8786)  Acc@1:  7.8125 ( 6.2732)  Acc@5: 35.9375 (31.0876)
Test: [ 150/575]  Time: 0.080 (0.082)  Loss:  2.8594 (2.8734)  Acc@1:  7.0312 ( 6.2914)  Acc@5: 32.8125 (31.1620)
Test: [ 200/575]  Time: 0.079 (0.081)  Loss:  2.9160 (2.8748)  Acc@1:  6.2500 ( 6.1995)  Acc@5: 30.4688 (31.0207)
Test: [ 250/575]  Time: 0.079 (0.081)  Loss:  2.9043 (2.8743)  Acc@1:  8.5938 ( 6.2375)  Acc@5: 32.8125 (31.0850)
Test: [ 300/575]  Time: 0.079 (0.081)  Loss:  2.8789 (2.8743)  Acc@1:  7.8125 ( 6.2396)  Acc@5: 34.3750 (31.0475)
Test: [ 350/575]  Time: 0.079 (0.080)  Loss:  2.9219 (2.8753)  Acc@1: 11.7188 ( 6.2611)  Acc@5: 29.6875 (31.0141)
Test: [ 400/575]  Time: 0.079 (0.080)  Loss:  2.8535 (2.8752)  Acc@1:  5.4688 ( 6.2208)  Acc@5: 34.3750 (30.9870)
Test: [ 450/575]  Time: 0.081 (0.080)  Loss:  2.8457 (2.8734)  Acc@1:  9.3750 ( 6.1876)  Acc@5: 31.2500 (31.1599)
Test: [ 500/575]  Time: 0.079 (0.080)  Loss:  2.8906 (2.8736)  Acc@1:  5.4688 ( 6.1642)  Acc@5: 25.7812 (31.0660)
Test: [ 550/575]  Time: 0.079 (0.080)  Loss:  2.8613 (2.8735)  Acc@1:  7.0312 ( 6.1734)  Acc@5: 26.5625 (31.1181)
Test: [ 575/575]  Time: 0.078 (0.080)  Loss:  2.8184 (2.8728)  Acc@1:  3.9062 ( 6.1849)  Acc@5: 28.1250 (31.1564)
Current checkpoints:
 ('/mnt/SFT_store/zxy/vit_small_patch16_224_in21k/vtab/dsprites_loc/ssf/20240127-023943-vit_small_patch16_224_in21k-224/checkpoint-1.pth.tar', 6.184895833333333)
 ('/mnt/SFT_store/zxy/vit_small_patch16_224_in21k/vtab/dsprites_loc/ssf/20240127-023943-vit_small_patch16_224_in21k-224/checkpoint-0.pth.tar', 6.182183159722222)

Train: 2 [   0/7 (  0%)]  Loss: 2.802 (2.80)  Time: 0.609s,  210.31/s  (0.609s,  210.31/s)  LR: 2.000e-03  Data: 0.393 (0.393)
Train: 2 [   6/7 (100%)]  Loss: 2.825 (2.81)  Time: 0.225s,  569.88/s  (0.274s,  466.88/s)  LR: 2.000e-03  Data: 0.000 (0.057)
Test: [   0/575]  Time: 0.614 (0.614)  Loss:  2.7598 (2.7598)  Acc@1:  9.3750 ( 9.3750)  Acc@5: 41.4062 (41.4062)
Test: [  50/575]  Time: 0.080 (0.092)  Loss:  2.7852 (2.7775)  Acc@1:  4.6875 ( 6.1887)  Acc@5: 32.8125 (35.5699)
Test: [ 100/575]  Time: 0.080 (0.086)  Loss:  2.7852 (2.7776)  Acc@1:  4.6875 ( 6.1804)  Acc@5: 37.5000 (35.1176)
Test: [ 150/575]  Time: 0.079 (0.084)  Loss:  2.7832 (2.7784)  Acc@1:  6.2500 ( 6.2293)  Acc@5: 35.9375 (34.8510)
Test: [ 200/575]  Time: 0.080 (0.083)  Loss:  2.7988 (2.7770)  Acc@1:  3.9062 ( 6.3277)  Acc@5: 32.8125 (35.1135)
Test: [ 250/575]  Time: 0.079 (0.082)  Loss:  2.7715 (2.7768)  Acc@1:  3.1250 ( 6.2936)  Acc@5: 35.1562 (35.2061)
